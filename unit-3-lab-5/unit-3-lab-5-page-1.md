# Analyzing U.S Baby Names

**On this page**, you will learn about the visualization of large data sets.

What about data with millions of pieces of information, instead of a few hundred? Large data sets present challenges and opportunities for discovering new information.

#### For You To Do

1. Using a Web browser, open the [Baby Name Voyager](http://www.babynamewizard.com/d3js-voyager/popup.html#prefix=&sw=both&exact=false). This visualization shows the 1000 most popular names of boys and girls born in the United States every year from 1880 to 2014.
2. What was the most popular girl's name in the 1900s? In the 1960s?

3. What boys' names are _much_ less popular today than they were in 1880?

4. Type in what you think is the most popular name in your school. Is this name still popular for new babies?

5. What else can you find? Find some interesting information in the data, then prepare to show it to your class.

6. Did you have trouble answering any of these questions? What, if anything, _doesn't _ this visualization do well? How might you improve it?

![](https://bjc.edc.org/bjc-r/img/5-algorithms/babypic.png "Baby Name Voyager")The Baby Name Voyager is an impressive visualization of a large data set. This data comes from the[Social Security Administration](https://www.ssa.gov/oact/babynames/limits.html), a text file for each year from 1880 to 2014. Very few of the insights in this data would be learned just from reading these files!

Large data sets present unique challenges and opportunities:

* Large data sets can be complex or nearly unmanageable. Storing, processing, and editing large data sets is difficult.

* Because of their size and complexity, large data sets can be difficult to usefully analyze. Computing power is frequently necessary for this analysis, providing access to trends or connections that would otherwise not be seen.

* One way in which computing power can be found for a massive computation is **crowdsourcing,** in which people all over the internet are asked to volunteer the time that their personal computers would otherwise spend doing nothing, e.g., while the person is asleep. Examples include SETI @ Home and Folding @ Home.

* Some large data sets are built by human collaboration, and can include text, sound, images, and video.

* Collaborative analysis is very useful when working with large data sets, often resulting in new information that could not be learned by an individual.
* Working with large data sets is often about making connections and identifying trends.
* Large data sets often contain personally identifiable information, such as names, locations, email addresses, and passwords. It can be difficult to work with large data sets while protecting personal privacy.

Visualizations and interactive tools are especially valuable

![](https://bjc.edc.org/bjc-r/img/5-algorithms/rundata.png "Running Data in NYC")

when working with large data sets, giving people the opportunity to study what might otherwise be incomprehensible. This map from [YesYesNo](https://vimeo.com/26399542) was generated from runners contributing their tracking data.

#### If There Is Time...

1. Work with the Social Security birth data to produce a visualization of your own. You can start with this 2014 data, with other years' data available here to download.

### Take It Further

1. Think of a large data source you've produced, and visualize it using Snap!. Remember, large data sets can include text, sound, images, and video.
  



